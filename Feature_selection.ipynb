{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection For Machine Learning in Python with scikit-learn\n",
    "Irrelevant or partially relevant features can negatively impact model performance. Select those features in your data that contribute most to the prediction variable to **Reduces Overfitting, Improves Accuracy, Reduces Training Time**\n",
    "\n",
    "Data set: SPECTF heart data intended for binary classification task.\n",
    "267 instances (train+test) are descibed by 45 attributes (44 continuous independent  + 1 binary dependent).\n",
    "All fields are numeric and there is no header line.\n",
    "Source: http://archive.ics.uci.edu/ml/machine-learning-databases/spect/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train set: (187, 45)\n",
      "Shape of test set: (80, 45)\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "names = [\"class\",\"F1R\", \"F1S\",\"F2R\",\"F2S\",\"F3R\",\"F3S\",\"F4R\",\"F4S\",\"F5R\",\"F5S\",\"F6R\",\"F6S\",\"F7R\",\"F7S\",\"F8R\",\"F8S\",\"F9R\",\n",
    "         \"F9S\",\"F10R\",\"F10S\",\"F11R\",\"F11S\",\"F12R\",\"F12S\",\"F13R\",\"F13S\",\"F14R\",\"F14S\",\"F15R\",\"F15S\",\"F16R\",\"F16S\",\n",
    "         \"F17R\",\"F17S\",\"F18R\",\"F18S\",\"F19R\",\"F19S\",\"F20R\",\"F20S\",\"F21R\",\"F21S\",\"F22R\",\"F22S\"] # 44 featires names\n",
    "### read train dataset\n",
    "filename_train = 'SPECTF.train.txt'\n",
    "dataframe_train = read_csv(filename_train, names=names)\n",
    "array_train = dataframe_train.values # convert to arrays from pandas.DataFrame\n",
    "print(\"Shape of train set: %s\" % str(array_train.shape))\n",
    "k_full = array_train.shape[1]-1\n",
    "X_train = array_train[:, 1:45]\n",
    "Y_train = array_train[:, 0:1]\n",
    "### read test dataset\n",
    "filename_test = 'SPECTF.test.txt'\n",
    "dataframe_test = read_csv(filename_test, names=names)\n",
    "array_test = dataframe_test.values # convert to arrays from pandas.DataFrame\n",
    "print(\"Shape of test set: %s\" % str(array_test.shape))\n",
    "X_test = array_test[:, 1:45]\n",
    "Y_test = array_test[:, 0:1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Univariate Selection\n",
    "(Chi-Squared) Statistical test for non-negative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.253  1.573  0.286  2.263  7.039 14.417  1.732  4.195  3.29   3.636\n",
      "  0.247  1.527  1.74   5.17   9.4   11.533  1.367  0.903  2.395  0.973\n",
      "  0.809  0.302  2.775  3.092 21.587 30.918  0.531  0.189  5.724  9.958\n",
      "  0.295  3.155  1.06   3.024  2.381  6.533  0.676  1.18  12.682 18.267\n",
      " 29.944 45.701 32.785 39.676]\n",
      "Accuracy using 44 features in Logistic model: 52.50%\n",
      "Accuracy using 40 features in Logistic model: 60.00%\n",
      "Eliminating 9% of features increased model accuracy by 7.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "# feature extraction\n",
    "k_trunkated=int(round(k_full*0.90)) # leave 90% of features\n",
    "train = SelectKBest(score_func=chi2, k=k_trunkated) # choose half top-features with the heights Chi-Squared statistics\n",
    "fit = train.fit(X_train, Y_train)\n",
    "# summarize scores\n",
    "set_printoptions(precision=3)\n",
    "print(fit.scores_) # Chi-Squared statistics for each feature - https://www.khanacademy.org/math/ap-statistics/chi-square-tests/chi-square-goodness-fit/v/chi-square-statistic\n",
    "features = fit.transform(X_train)\n",
    "\n",
    "# feature extraction\n",
    "features_test = fit.transform(X_test)\n",
    "# apply Logistac model to the full feature set\n",
    "model_full = LogisticRegression()\n",
    "model_full.fit(X_train, Y_train.ravel())\n",
    "result_full = model_full.score(X_test, Y_test.ravel())\n",
    "print(\"Accuracy using %d features in Logistic model: %.2f%%\" % (k_full,(result_full*100.0)))\n",
    "\n",
    "# apply Logistac model to the most important features\n",
    "model_trunkated = LogisticRegression()\n",
    "model_trunkated.fit(features, Y_train.ravel())\n",
    "result_trunkated = model_trunkated.score(features_test, Y_test.ravel())\n",
    "print(\"Accuracy using %d features in Logistic model: %.2f%%\" % (k_trunkated, (result_trunkated*100.0)))\n",
    "print(\"Eliminating %d%% of features increased model accuracy by %.1f%%\" % (int(round((k_full-k_trunkated)*100/k_full)), (result_trunkated-result_full)*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Recursive Feature Elimination (RFE)\n",
    "It uses the model accuracy to identify which attributes (and combination of attributes) contribute the most to predicting the target attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 40\n",
      "Selected Features: [ True  True  True  True  True  True  True  True  True  True  True False\n",
      "  True  True  True  True  True  True False  True  True  True False  True\n",
      "  True False  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True]\n",
      "Feature Ranking: [1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 5 1 1 1 3 1 1 4 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1]\n",
      "(80, 40)\n",
      "Accuracy using 44 features in Logistic model: 52.50%\n",
      "Accuracy using 40 features in Logistic model: 53.75%\n",
      "Eliminating 9% of features increased model accuracy by 1.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "model_full = LogisticRegression()\n",
    "k_full = array_train.shape[1]-1\n",
    "k_truncated=int(round(k_full*0.9))\n",
    "rfe = RFE(model_full, k_truncated)\n",
    "fit = rfe.fit(X_train, Y_train.ravel())\n",
    "print(\"Num Features: %d\" % fit.n_features_)\n",
    "print(\"Selected Features: %s\" % fit.support_)\n",
    "print(\"Feature Ranking: %s\" % fit.ranking_)\n",
    "features = fit.transform(X_train)\n",
    "features_test = fit.transform(X_test)\n",
    "print(features_test.shape)\n",
    "\n",
    "# apply Logistac model to the full feature set\n",
    "model_full.fit(X_train, Y_train.ravel())\n",
    "result_full = model_full.score(X_test, Y_test.ravel())\n",
    "print(\"Accuracy using %d features in Logistic model: %.2f%%\" % (k_full,(result_full*100.0)))\n",
    "\n",
    "# apply Logistac model to the most important features\n",
    "model_truncated = LogisticRegression()\n",
    "model_truncated.fit(features, Y_train.ravel())\n",
    "result_truncated = model_truncated.score(features_test, Y_test.ravel())\n",
    "print(\"Accuracy using %d features in Logistic model: %.2f%%\" % (k_truncated, (result_truncated*100.0)))\n",
    "print(\"Eliminating %d%% of features increased model accuracy by %.2f%%\" % (int(round((k_full-k_truncated)*100/k_full)), (result_truncated-result_full)*100.0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Principal Component Analysis\n",
    "It uses linear algebra to transform the dataset into a compressed form. (Dimensionality Reduction Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance: [0.4   0.149 0.072 0.049 0.037 0.033 0.028 0.024 0.021 0.02  0.017 0.015\n",
      " 0.013 0.011 0.01  0.009 0.009 0.008 0.007 0.007 0.006 0.005 0.005 0.004\n",
      " 0.004 0.004 0.003 0.003 0.003 0.003 0.002 0.002 0.002 0.002 0.002]\n",
      "Accuracy using 44 features in Logistic model: 52.50%\n",
      "Accuracy using 35 features in Logistic model: 62.50%\n",
      "Eliminating 20% of features increased model accuracy by 10.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "k_full = array_train.shape[1]-1\n",
    "k_truncated=int(round(k_full*0.8))\n",
    "pca = PCA(n_components=k_truncated)\n",
    "fit = pca.fit(X_train)\n",
    "# summarize components\n",
    "print(\"Explained Variance: %s\" % fit.explained_variance_ratio_)\n",
    "#print(fit.components_)\n",
    "features = fit.transform(X_train)\n",
    "features_test = fit.transform(X_test)\n",
    "\n",
    "# apply Logistac model to the full feature set\n",
    "model_full = LogisticRegression()\n",
    "model_full.fit(X_train, Y_train.ravel())\n",
    "result_full = model_full.score(X_test, Y_test.ravel())\n",
    "print(\"Accuracy using %d features in Logistic model: %.2f%%\" % (k_full,(result_full*100.0)))\n",
    "\n",
    "# apply Logistac model to the most important features\n",
    "model_truncated = LogisticRegression()\n",
    "model_truncated.fit(features, Y_train.ravel())\n",
    "result_truncated = model_truncated.score(features_test, Y_test.ravel())\n",
    "print(\"Accuracy using %d features in Logistic model: %.2f%%\" % (k_truncated, (result_truncated*100.0)))\n",
    "print(\"Eliminating %d%% of features increased model accuracy by %.2f%%\" % (int(round((k_full-k_truncated)*100/k_full)), (result_truncated-result_full)*100.0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Feature Importance\n",
    "It fits a number of randomized decision trees (Extra-trees) on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(187, 44)\n",
      "44\n",
      "[0.031 0.033 0.022 0.016 0.027 0.024 0.022 0.023 0.037 0.041 0.019 0.006\n",
      " 0.015 0.008 0.027 0.007 0.014 0.022 0.018 0.026 0.039 0.012 0.036 0.015\n",
      " 0.013 0.042 0.035 0.01  0.015 0.018 0.007 0.03  0.026 0.013 0.022 0.001\n",
      " 0.005 0.024 0.013 0.022 0.055 0.042 0.031 0.034]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "print(X_train.shape)\n",
    "model_full = ExtraTreesClassifier()\n",
    "model_full.fit(X_train, Y_train.ravel())\n",
    "print(model_full.n_features_)\n",
    "print(model_full.feature_importances_)\n",
    "features = fit.transform(X_train)\n",
    "features_test = fit.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
